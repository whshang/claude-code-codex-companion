package proxy

import (
	"fmt"
	"path/filepath"
	"sync"
	"time"

	"claude-code-codex-companion/internal/config"
	"claude-code-codex-companion/internal/conversion"
	"claude-code-codex-companion/internal/database"
	"claude-code-codex-companion/internal/endpoint"
	"claude-code-codex-companion/internal/health"
	"claude-code-codex-companion/internal/logger"
	"claude-code-codex-companion/internal/modelrewrite"
	"claude-code-codex-companion/internal/statistics"
	"claude-code-codex-companion/internal/utils" // æ–°å¢ï¼šå¯¼å…¥utilsåŒ…
	"claude-code-codex-companion/internal/validator"

	"github.com/gin-gonic/gin"
)

type Server struct {
	config          *config.Config
	endpointManager *endpoint.Manager
	logger          *logger.Logger
	validator       *validator.ResponseValidator
	healthChecker   *health.Checker
	modelRewriter   *modelrewrite.Rewriter // æ–°å¢ï¼šæ¨¡å‹é‡å†™å™¨
	router          *gin.Engine
	configFilePath  string
	configMutex     sync.Mutex // æ–°å¢ï¼šä¿æŠ¤é…ç½®æ–‡ä»¶æ“ä½œçš„äº’æ–¥é”

	// Conversion manager for format adaptation
	conversionManager *conversion.ConversionManager

	// åŠ¨æ€ç«¯ç‚¹æ’åºå™¨
	dynamicSorter *utils.DynamicEndpointSorter

	// é…ç½®æŒä¹…åŒ–ç®¡ç†å™¨
	configPersister *config.ConfigPersister

	// é”™è¯¯æ¨¡å¼åŒ¹é…å™¨
	errorPatternMatcher *ErrorPatternMatcher
}

func NewServer(cfg *config.Config, configFilePath string, version string) (*Server, error) {
	// è·å–å…¨å±€æ•°æ®åº“ç®¡ç†å™¨
	dbManager, err := database.GetGlobalManager()
	if err != nil {
		return nil, fmt.Errorf("failed to get database manager: %w", err)
	}

    // ç»Ÿä¸€æ—¥å¿—ä¸ç»Ÿè®¡ç›®å½•ï¼šå°†é…ç½®ä¸­çš„æ—¥å¿—ç›®å½•è¦†ç›–ä¸ºæ•°æ®åº“ç®¡ç†å™¨æ‰€åœ¨ç›®å½•
    // ç¡®ä¿ Endpoint ç»Ÿè®¡ä¸ GORM æ—¥å¿—ä½¿ç”¨åŒä¸€ç›®å½•ï¼ˆå³ dataDirï¼‰
    cfg.Logging.LogDirectory = filepath.Dir(dbManager.GetLogsDBPath())

	// ä½¿ç”¨ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨çš„æ—¥å¿—è·¯å¾„
    logConfig := logger.LogConfig{
		Level:           cfg.Logging.Level,
		LogRequestTypes: cfg.Logging.LogRequestTypes,
		LogRequestBody:  cfg.Logging.LogRequestBody,
		LogResponseBody: cfg.Logging.LogResponseBody,
        LogDirectory:    filepath.Dir(dbManager.GetLogsDBPath()),
		ExcludePaths:    cfg.Logging.ExcludePaths,
	}

	log, err := logger.NewLogger(logConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize logger: %v", err)
	}

	endpointManager, err := endpoint.NewManager(cfg)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize endpoint manager: %v", err)
	}
	responseValidator := validator.NewResponseValidator()

	// åˆå§‹åŒ–æ¨¡å‹é‡å†™å™¨
	modelRewriter := modelrewrite.NewRewriter(*log)

	// åˆå§‹åŒ–å¥åº·æ£€æŸ¥å™¨ï¼ˆéœ€è¦åœ¨æ¨¡å‹é‡å†™å™¨ä¹‹åï¼‰
	healthChecker := health.NewChecker(cfg.Timeouts.ToHealthCheckTimeoutConfig(), modelRewriter, config.Default.HealthCheck.Model)

	manager := conversion.NewConversionManager(log, conversion.ManagerConfig{
		Mode:              conversion.ConversionMode(cfg.Conversion.AdapterMode),
		FailbackThreshold: cfg.Conversion.FailbackThreshold,
		ValidateSwitch:    cfg.Conversion.ValidateModeSwitch,
	})

	server := &Server{
		config:          cfg,
		endpointManager: endpointManager,
		logger:          log,
		validator:       responseValidator,
		healthChecker:   healthChecker,
		modelRewriter:   modelRewriter, // æ–°å¢ï¼šè®¾ç½®æ¨¡å‹é‡å†™å™¨
		configFilePath:  configFilePath,
	}

	// åˆå§‹åŒ–åŠ¨æ€ç«¯ç‚¹æ’åºå™¨
	server.dynamicSorter = utils.NewDynamicEndpointSorter()

	// åˆ›å»ºé…ç½®æŒä¹…åŒ–ç®¡ç†å™¨
	flushInterval := 30 * time.Second // é»˜è®¤30ç§’
	maxDirtyTime := 5 * time.Minute   // é»˜è®¤5åˆ†é’Ÿ

	// ä»é…ç½®ä¸­è¯»å–è‡ªå®šä¹‰å€¼
	if cfg.Server.ConfigFlushInterval != "" {
		if duration, err := time.ParseDuration(cfg.Server.ConfigFlushInterval); err == nil {
			flushInterval = duration
		} else {
			log.Error("Invalid config_flush_interval, using default 30s", err)
		}
	}
	if cfg.Server.ConfigMaxDirtyTime != "" {
		if duration, err := time.ParseDuration(cfg.Server.ConfigMaxDirtyTime); err == nil {
			maxDirtyTime = duration
		} else {
			log.Error("Invalid config_max_dirty_time, using default 5m", err)
		}
	}

	persister := config.NewConfigPersister(cfg, configFilePath, &config.PersisterConfig{
		FlushInterval: flushInterval,
		MaxDirtyTime:  maxDirtyTime,
		BeforeWrite: func(c *config.Config) error {
			// å†™å…¥å‰éªŒè¯
			if len(c.Endpoints) == 0 {
				return fmt.Errorf("configuration must have at least one endpoint")
			}
			return nil
		},
		AfterWrite: func(c *config.Config) error {
			// å†™å…¥åé€šçŸ¥
			log.Info("âœ… Configuration successfully persisted")
			return nil
		},
	})

	server.configPersister = persister

	// å¯åŠ¨æŒä¹…åŒ–ç®¡ç†å™¨
	persister.Start()

	server.conversionManager = manager

	// åˆå§‹åŒ–é”™è¯¯æ¨¡å¼åŒ¹é…å™¨
	server.errorPatternMatcher = NewErrorPatternMatcher()

	// è®¾ç½®åŠ¨æ€æ’åºå™¨çš„æŒä¹…åŒ–å›è°ƒ
	server.dynamicSorter.SetPersistCallback(func() error {
		return server.PersistEndpointPriorityChanges()
	})

	// è®©ç«¯ç‚¹ç®¡ç†å™¨ä½¿ç”¨åŒä¸€ä¸ªå¥åº·æ£€æŸ¥å™¨
	endpointManager.SetHealthChecker(healthChecker)

	server.setupRoutes()
	return server, nil
}

func (s *Server) setupRoutes() {
	gin.SetMode(gin.ReleaseMode)

	s.router = gin.New()
	s.router.Use(gin.Recovery())
	s.router.UseRawPath = true
	s.router.UnescapePathValues = false

	// æ·»åŠ CORSä¸­é—´ä»¶
	s.router.Use(func(c *gin.Context) {
		c.Header("Access-Control-Allow-Origin", "*")
		c.Header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
		c.Header("Access-Control-Allow-Headers", "Origin, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization")

		if c.Request.Method == "OPTIONS" {
			c.AbortWithStatus(204)
			return
		}

		c.Next()
	})

	// ä¸º API ç«¯ç‚¹æ·»åŠ æ—¥å¿—ä¸­é—´ä»¶
	apiGroup := s.router.Group("/v1")
	apiGroup.Use(s.loggingMiddleware())
	{
		apiGroup.Any("/*path", s.handleProxy)
	}

	// æ”¯æŒ Codex çš„ /responses è·¯å¾„
	s.router.Any("/responses", s.loggingMiddleware(), s.handleProxy)
	s.router.Any("/chat/completions", s.loggingMiddleware(), s.handleProxy)

	// æ”¯æŒæ¨¡å‹åˆ—è¡¨ APIï¼ˆç”± handleProxy å†…éƒ¨ç‰¹æ®Šå¤„ç†ï¼‰
}

// Start starts the proxy server
func (s *Server) Start() error {
	// ğŸ”¥ VERSION CHECK: ç¡®è®¤ä»£ç å·²ç¼–è¯‘
	s.logger.Info("ğŸš€ğŸš€ğŸš€ PROXY SERVER VERSION: PATH_CONVERSION_FIX_v2 ğŸš€ğŸš€ğŸš€")
	
	// æ ¹æ®é…ç½®å¯ç”¨åŠ¨æ€æ’åº
	if s.config.Server.AutoSortEndpoints {
		s.dynamicSorter.Enable()
		// å°†ç«¯ç‚¹è½¬æ¢ä¸ºåŠ¨æ€ç«¯ç‚¹ç±»å‹å¹¶è®¾ç½®å¼•ç”¨
		dynamicEndpoints := make([]utils.DynamicEndpoint, 0)
		for _, ep := range s.endpointManager.GetAllEndpoints() {
			ep.SetDynamicSorter(s.dynamicSorter)
			dynamicEndpoints = append(dynamicEndpoints, ep)
		}
		s.dynamicSorter.SetEndpoints(dynamicEndpoints)
		s.logger.Info("âœ… å¯ç”¨åŠ¨æ€ç«¯ç‚¹æ’åºåŠŸèƒ½")
	} else {
		s.logger.Info("â„¹ï¸ åŠ¨æ€ç«¯ç‚¹æ’åºåŠŸèƒ½å·²ç¦ç”¨")
	}

	addr := fmt.Sprintf("%s:%d", s.config.Server.Host, s.config.Server.Port)
	s.logger.Info(fmt.Sprintf("Starting proxy server on %s:%d", s.config.Server.Host, s.config.Server.Port))
	return s.router.Run(addr)
}

func (s *Server) GetRouter() *gin.Engine {
	return s.router
}

func (s *Server) GetEndpointManager() *endpoint.Manager {
	return s.endpointManager
}

func (s *Server) GetLogger() *logger.Logger {
	return s.logger
}

func (s *Server) GetHealthChecker() *health.Checker {
	return s.healthChecker
}

// HotUpdateConfig safely updates configuration without restarting the server
func (s *Server) HotUpdateConfig(newConfig *config.Config) error {
	// éªŒè¯æ–°é…ç½®
	if err := s.validateConfigForHotUpdate(newConfig); err != nil {
		return fmt.Errorf("invalid configuration: %v", err)
	}

	s.logger.Info("Starting configuration hot update")

	// æ›´æ–°ç«¯ç‚¹é…ç½®
	if err := s.updateEndpoints(newConfig.Endpoints); err != nil {
		return fmt.Errorf("failed to update endpoints: %v", err)
	}

	// æ›´æ–°æ—¥å¿—é…ç½®ï¼ˆå¦‚æœå¯èƒ½ï¼‰
	if err := s.updateLoggingConfig(newConfig.Logging); err != nil {
		s.logger.Error("Failed to update logging config, continuing with endpoint updates", err)
	}

	// æ›´æ–°éªŒè¯å™¨é…ç½®
	s.updateValidatorConfig(newConfig.Validation)

	// æ›´æ–°é»‘åå•é…ç½®
	s.updateBlacklistConfig(newConfig.Blacklist)

	// æ›´æ–°å†…å­˜ä¸­çš„é…ç½®ï¼ˆéœ€è¦é”ä¿æŠ¤ï¼Œå› ä¸ºå¯èƒ½ä¸å…¶ä»–é…ç½®æ›´æ–°å¹¶å‘ï¼‰
	s.configMutex.Lock()
	s.config = newConfig
	s.configMutex.Unlock()

	if s.configPersister != nil {
		s.configPersister.UpdateConfig(newConfig)
	}

	if s.conversionManager != nil {
		if err := s.conversionManager.ApplyConfig(conversion.ManagerConfig{
			Mode:              conversion.ConversionMode(newConfig.Conversion.AdapterMode),
			FailbackThreshold: newConfig.Conversion.FailbackThreshold,
			ValidateSwitch:    newConfig.Conversion.ValidateModeSwitch,
		}); err != nil {
			s.logger.Error("Failed to apply conversion configuration during hot update", err)
		}
	}

	s.logger.Info("Configuration hot update completed successfully")
	return nil
}

// validateConfigForHotUpdate validates the new configuration
func (s *Server) validateConfigForHotUpdate(newConfig *config.Config) error {
	// æ£€æŸ¥æ˜¯å¦å°è¯•ä¿®æ”¹ä¸å¯çƒ­æ›´æ–°çš„é…ç½®
	if newConfig.Server.Host != s.config.Server.Host {
		return fmt.Errorf("server host cannot be changed via hot update")
	}
	if newConfig.Server.Port != s.config.Server.Port {
		return fmt.Errorf("server port cannot be changed via hot update")
	}

	// éªŒè¯ç«¯ç‚¹é…ç½®
	if len(newConfig.Endpoints) == 0 {
		return fmt.Errorf("at least one endpoint must be configured")
	}

	return nil
}

// updateEndpoints updates endpoint configuration
func (s *Server) updateEndpoints(newEndpoints []config.EndpointConfig) error {
	s.endpointManager.UpdateEndpoints(newEndpoints)

	// å¦‚æœåŠ¨æ€æ’åºå·²å¯ç”¨ï¼Œéœ€è¦æ›´æ–°dynamicSorterçš„endpointsåˆ—è¡¨
	if s.config.Server.AutoSortEndpoints && s.dynamicSorter != nil {
		dynamicEndpoints := make([]utils.DynamicEndpoint, 0)
		for _, ep := range s.endpointManager.GetAllEndpoints() {
			ep.SetDynamicSorter(s.dynamicSorter)
			dynamicEndpoints = append(dynamicEndpoints, ep)
		}
		s.dynamicSorter.SetEndpoints(dynamicEndpoints)
		s.logger.Info("ğŸ”„ åŠ¨æ€æ’åºå™¨çš„ç«¯ç‚¹åˆ—è¡¨å·²æ›´æ–°")
	}

	return nil
}

// updateLoggingConfig updates logging configuration if possible
func (s *Server) updateLoggingConfig(newLogging config.LoggingConfig) error {
	// ç›®å‰åªèƒ½æ›´æ–°æ—¥å¿—çº§åˆ«å’Œè®°å½•ç­–ç•¥ï¼Œä¸èƒ½æ›´æ¢æ—¥å¿—ç›®å½•
	if newLogging.LogDirectory != s.config.Logging.LogDirectory {
		return fmt.Errorf("log directory cannot be changed via hot update")
	}

	// å¯ä»¥å®‰å…¨æ›´æ–°çš„æ—¥å¿—é…ç½®
	s.config.Logging.Level = newLogging.Level
	s.config.Logging.LogRequestTypes = newLogging.LogRequestTypes
	s.config.Logging.LogRequestBody = newLogging.LogRequestBody
	s.config.Logging.LogResponseBody = newLogging.LogResponseBody
	s.config.Logging.ExcludePaths = newLogging.ExcludePaths

	// æ›´æ–°loggerçš„é…ç½®
	s.logger.UpdateConfig(logger.LogConfig{
		Level:           newLogging.Level,
		LogRequestTypes: newLogging.LogRequestTypes,
		LogRequestBody:  newLogging.LogRequestBody,
		LogResponseBody: newLogging.LogResponseBody,
		LogDirectory:    newLogging.LogDirectory,
		ExcludePaths:    newLogging.ExcludePaths,
	})

	return nil
}

// updateValidatorConfig updates response validator configuration
func (s *Server) updateValidatorConfig(newValidation config.ValidationConfig) {
	s.validator = validator.NewResponseValidator()
	s.config.Validation = newValidation
}

// updateBlacklistConfig updates blacklist configuration
func (s *Server) updateBlacklistConfig(newBlacklist config.BlacklistConfig) {
	s.config.Blacklist = newBlacklist
}

// saveConfigToFile å°†å½“å‰é…ç½®ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
func (s *Server) saveConfigToFile() error {
	// æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å‡è®¾è°ƒç”¨è€…å·²ç»æŒæœ‰ configMutex
	// å¦‚æœ ConfigPersister å­˜åœ¨ï¼Œä½¿ç”¨å®ƒï¼ˆç«‹å³å†™å…¥ï¼‰
	if s.configPersister != nil {
		return s.configPersister.FlushNow()
	}
	// å¦åˆ™ç›´æ¥ä¿å­˜ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
	return config.SaveConfig(s.config, s.configFilePath)
}

// GetConfigPersister è·å–é…ç½®æŒä¹…åŒ–ç®¡ç†å™¨
func (s *Server) GetConfigPersister() *config.ConfigPersister {
	return s.configPersister
}

// Shutdown ä¼˜é›…å…³é—­æœåŠ¡å™¨ï¼Œç¡®ä¿æ‰€æœ‰å¾…å¤„ç†çš„é…ç½®è¢«ä¿å­˜
func (s *Server) Shutdown() error {
	s.logger.Info("Shutting down server...")

	// åœæ­¢é…ç½®æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆä¼šè‡ªåŠ¨å†™å…¥æœªä¿å­˜çš„å˜æ›´ï¼‰
	if s.configPersister != nil {
		if err := s.configPersister.Stop(); err != nil {
			s.logger.Error("Failed to stop config persister", err)
			return err
		}
	}

	// ç¦ç”¨åŠ¨æ€æ’åºå™¨
	if s.dynamicSorter != nil {
		s.dynamicSorter.Disable()
	}

	s.logger.Info("Server shutdown complete")
	return nil
}

// updateEndpointConfig å®‰å…¨åœ°æ›´æ–°æŒ‡å®šç«¯ç‚¹çš„é…ç½®å¹¶æŒä¹…åŒ–
func (s *Server) updateEndpointConfig(endpointName string, updateFunc func(*config.EndpointConfig) error) error {
	s.configMutex.Lock()
	defer s.configMutex.Unlock()

	// æŸ¥æ‰¾å¯¹åº”çš„ç«¯ç‚¹é…ç½®
	for i, cfgEndpoint := range s.config.Endpoints {
		if cfgEndpoint.Name == endpointName {
			// åº”ç”¨æ›´æ–°å‡½æ•°
			if err := updateFunc(&s.config.Endpoints[i]); err != nil {
				return err
			}

			// ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
			return s.saveConfigToFile()
		}
	}

	return fmt.Errorf("endpoint not found: %s", endpointName)
}

// createOAuthTokenRefreshCallback åˆ›å»º OAuth token åˆ·æ–°åçš„å›è°ƒå‡½æ•°
func (s *Server) createOAuthTokenRefreshCallback() func(*endpoint.Endpoint) error {
	return func(ep *endpoint.Endpoint) error {
		// ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ›´æ–°æœºåˆ¶
		return s.updateEndpointConfig(ep.Name, func(cfg *config.EndpointConfig) error {
			cfg.OAuthConfig = ep.OAuthConfig
			return nil
		})
	}
}

// persistRateLimitState æŒä¹…åŒ–endpointçš„rate limitçŠ¶æ€åˆ°é…ç½®æ–‡ä»¶
func (s *Server) persistRateLimitState(endpointID string, reset *int64, status *string) error {
	// é¦–å…ˆæ ¹æ®endpoint IDæ‰¾åˆ°å¯¹åº”çš„endpointåç§°
	var endpointName string
	s.configMutex.Lock()
	for _, cfgEndpoint := range s.config.Endpoints {
		if statistics.GenerateEndpointID(cfgEndpoint.Name) == endpointID {
			endpointName = cfgEndpoint.Name
			break
		}
	}
	s.configMutex.Unlock()

	if endpointName == "" {
		return fmt.Errorf("endpoint with ID %s not found", endpointID)
	}

	// ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ›´æ–°æœºåˆ¶
	return s.updateEndpointConfig(endpointName, func(cfg *config.EndpointConfig) error {
		cfg.RateLimitReset = reset
		cfg.RateLimitStatus = status
		return nil
	})
}

// PersistEndpointPriorityChanges æŒä¹…åŒ–ç«¯ç‚¹ä¼˜å…ˆçº§æ›´æ”¹åˆ°é…ç½®æ–‡ä»¶
// æ³¨æ„ï¼šæ­¤æ–¹æ³•ç”± DynamicSorter è°ƒç”¨ï¼Œåº”æ ‡è®°ä¸ºè„æ•°æ®è€Œéç«‹å³å†™å…¥
func (s *Server) PersistEndpointPriorityChanges() error {
	s.configMutex.Lock()
	defer s.configMutex.Unlock()

	// è·å–æ‰€æœ‰ç«¯ç‚¹å¹¶æŒ‰ä¼˜å…ˆçº§æ’åº
	endpoints := s.endpointManager.GetAllEndpoints()

	// åˆ›å»ºç«¯ç‚¹åç§°åˆ°ä¼˜å…ˆçº§çš„æ˜ å°„
	priorityMap := make(map[string]int)
	for _, ep := range endpoints {
		// æ‰€æœ‰ç«¯ç‚¹ï¼ˆæ— è®ºå¯ç”¨æˆ–ç¦ç”¨ï¼‰çš„ä¼˜å…ˆçº§éƒ½éœ€è¦æŒä¹…åŒ–
		priorityMap[ep.Name] = ep.GetPriority()
	}

	// æ›´æ–°é…ç½®ä¸­çš„ç«¯ç‚¹ä¼˜å…ˆçº§
	updated := false
	for i, cfgEndpoint := range s.config.Endpoints {
		if priority, exists := priorityMap[cfgEndpoint.Name]; exists {
			if s.config.Endpoints[i].Priority != priority {
				s.config.Endpoints[i].Priority = priority
				updated = true
				s.logger.Info(fmt.Sprintf("ğŸ”„ æ›´æ–°ç«¯ç‚¹ '%s' çš„ä¼˜å…ˆçº§ä¸º %d", cfgEndpoint.Name, priority))
			}
		}
	}

	// å¦‚æœæœ‰æ›´æ–°ï¼Œæ ‡è®°ä¸ºè„æ•°æ®ï¼ˆç”±åŠ¨æ€æ’åºè§¦å‘ï¼Œä¸ç«‹å³å†™å…¥ï¼‰
	if updated && s.configPersister != nil {
		s.configPersister.MarkDirty()
	}

	return nil
}

// PersistEndpointLearning æŒä¹…åŒ–ç«¯ç‚¹å­¦ä¹ åˆ°çš„é…ç½®
func (s *Server) PersistEndpointLearning(ep *endpoint.Endpoint) {
	// çº¿ç¨‹å®‰å…¨ï¼šè·å–ç«¯ç‚¹å½“å‰çš„å­¦ä¹ çŠ¶æ€
	ep.AuthHeaderMutex.RLock()
	detectedAuthHeader := ep.DetectedAuthHeader
	ep.AuthHeaderMutex.RUnlock()

	openAIPreference := ep.OpenAIPreference
	countTokensEnabled := ep.CountTokensEnabled
	supportsResponses := ep.NativeCodexFormat
	if supportsResponses == nil {
		ep.SupportsResponses = nil
	}

	// è°ƒç”¨ AdminServer çš„æŒä¹…åŒ–æ–¹æ³•
	// åªæœ‰åœ¨å­¦ä¹ åˆ°æ–°ä¿¡æ¯æ—¶æ‰æŒä¹…åŒ–
	needsPersist := false

	// 1. æ£€æŸ¥è®¤è¯æ–¹å¼æ˜¯å¦éœ€è¦æŒä¹…åŒ–
	if detectedAuthHeader != "" && (ep.AuthType == "" || ep.AuthType == "auto") {
		// ä»æ£€æµ‹åˆ°çš„å¤´éƒ¨ç±»å‹æ¨æ–­è®¤è¯ç±»å‹
		var authType string
		if detectedAuthHeader == "api_key" || detectedAuthHeader == "x-api-key" {
			authType = "api_key"
		} else {
			authType = "auth_token"
		}

		// åªæœ‰å½“é…ç½®ä¸­çš„è®¤è¯ç±»å‹ä¸æ£€æµ‹åˆ°çš„ä¸åŒæ—¶æ‰æ›´æ–°
		if ep.AuthType != authType {
			s.logger.Info(fmt.Sprintf("ğŸ” Learning: Detected auth type '%s' for endpoint '%s'", authType, ep.Name), nil)

			// ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ›´æ–°æœºåˆ¶æŒä¹…åŒ–è®¤è¯ç±»å‹
			if err := s.updateEndpointConfig(ep.Name, func(cfg *config.EndpointConfig) error {
				cfg.AuthType = authType
				return nil
			}); err != nil {
				s.logger.Error(fmt.Sprintf("Failed to persist auth type for endpoint '%s'", ep.Name), err)
			} else {
				s.logger.Info(fmt.Sprintf("âœ“ Persisted auth type '%s' for endpoint '%s'", authType, ep.Name), nil)
				needsPersist = true
			}
		}
	}

	// 2. æ£€æŸ¥ OpenAI æ ¼å¼åå¥½æ˜¯å¦éœ€è¦æŒä¹…åŒ–
	if openAIPreference != "" && openAIPreference != "auto" {
		s.configMutex.Lock()
		configPreference := ""
		for i := range s.config.Endpoints {
			if s.config.Endpoints[i].Name == ep.Name {
				configPreference = s.config.Endpoints[i].OpenAIPreference
				break
			}
		}
		s.configMutex.Unlock()

		// åªæœ‰å½“é…ç½®ä¸­çš„åå¥½ä¸å½“å‰å­¦ä¹ åˆ°çš„ä¸åŒæ—¶æ‰æ›´æ–°
		if configPreference == "" || configPreference == "auto" || configPreference != openAIPreference {
			s.logger.Info(fmt.Sprintf("ğŸ” Learning: Detected OpenAI format preference '%s' for endpoint '%s'", openAIPreference, ep.Name), nil)

			// ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ›´æ–°æœºåˆ¶æŒä¹…åŒ– OpenAI æ ¼å¼åå¥½
			if err := s.updateEndpointConfig(ep.Name, func(cfg *config.EndpointConfig) error {
				cfg.OpenAIPreference = openAIPreference
				return nil
			}); err != nil {
				s.logger.Error(fmt.Sprintf("Failed to persist OpenAI preference for endpoint '%s'", ep.Name), err)
			} else {
				s.logger.Info(fmt.Sprintf("âœ“ Persisted OpenAI preference '%s' for endpoint '%s'", openAIPreference, ep.Name), nil)
				needsPersist = true
			}
		}
	}

	// 3. æŒä¹…åŒ–å¯¹ /responses æ”¯æŒçš„å­¦ä¹ ç»“æœ
	if supportsResponses != nil {
		var configSupportsValue bool
		configSupportsSet := false
		s.configMutex.Lock()
		for i := range s.config.Endpoints {
			if s.config.Endpoints[i].Name == ep.Name {
				if s.config.Endpoints[i].SupportsResponses != nil {
					configSupportsValue = *s.config.Endpoints[i].SupportsResponses
					configSupportsSet = true
				}
				break
			}
		}
		s.configMutex.Unlock()

		if !configSupportsSet || configSupportsValue != *supportsResponses {
			s.logger.Info(fmt.Sprintf("ğŸ§­ Learning: Detected supports_responses=%v for endpoint '%s'", *supportsResponses, ep.Name), nil)
			supported := *supportsResponses
			if err := s.updateEndpointConfig(ep.Name, func(cfg *config.EndpointConfig) error {
				ptr := new(bool)
				*ptr = supported
				cfg.SupportsResponses = ptr
				return nil
			}); err != nil {
				s.logger.Error(fmt.Sprintf("Failed to persist supports_responses for endpoint '%s'", ep.Name), err)
			} else {
				s.logger.Info(fmt.Sprintf("âœ“ Persisted supports_responses=%v for endpoint '%s'", supported, ep.Name), nil)
				needsPersist = true
				copyVal := supported
				ep.SupportsResponses = &copyVal
			}
		}
	}

	// 5. count_tokens å¯ç”¨æ€§ï¼ˆä»…åœ¨éœ€è¦æ—¶æŒä¹…åŒ–ï¼‰
	if !countTokensEnabled {
		if err := s.updateEndpointConfig(ep.Name, func(cfg *config.EndpointConfig) error {
			if cfg.CountTokensEnabled != nil && *cfg.CountTokensEnabled == countTokensEnabled {
				return nil
			}
			ptr := new(bool)
			*ptr = countTokensEnabled
			cfg.CountTokensEnabled = ptr
			return nil
		}); err != nil {
			s.logger.Error(fmt.Sprintf("Failed to persist count_tokens flag for endpoint '%s'", ep.Name), err)
		} else {
			s.logger.Info(fmt.Sprintf("âœ“ Persisted count_tokens_enabled=%v for endpoint '%s'", countTokensEnabled, ep.Name), nil)
			needsPersist = true
		}
	}

	if needsPersist {
		s.logger.Info(fmt.Sprintf("ğŸ“ Successfully persisted learned configuration for endpoint '%s'", ep.Name), nil)
	}
}
