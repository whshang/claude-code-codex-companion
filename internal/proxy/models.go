package proxy

import (
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"

	"claude-code-codex-companion/internal/endpoint"
	jsonutils "claude-code-codex-companion/internal/common/json"
	"github.com/gin-gonic/gin"
)

// models.go: æ¨¡å‹åˆ—è¡¨æ¨¡å—
// è´Ÿè´£å¤„ç† /v1/models ç«¯ç‚¹çš„é€»è¾‘ã€‚
//
// ç›®æ ‡ï¼š
// - åŒ…å« handleModelsList å‡½æ•°åŠå…¶æ‰€æœ‰è¾…åŠ©å‡½æ•°ã€‚
// - è´Ÿè´£ä»ä¸åŒçš„ä¸Šæ¸¸ç«¯ç‚¹è·å–æ¨¡å‹åˆ—è¡¨ã€‚
// - å°†ä¸åŒæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨å“åº”èšåˆå¹¶è½¬æ¢ä¸ºå®¢æˆ·ç«¯æœŸæœ›çš„æ ¼å¼ã€‚

func (s *Server) handleModelsList(c *gin.Context) {
	requestID := c.GetString("request_id")
	if requestID == "" {
		requestID = fmt.Sprintf("models-%d", time.Now().UnixNano())
		c.Set("request_id", requestID)
	}

	path := c.Request.URL.Path
	s.logger.Info("ğŸ“‹ Models list request", map[string]interface{}{
		"request_id": requestID,
		"path":       path,
	})

	// æ£€æµ‹å®¢æˆ·ç«¯æ ¼å¼
	clientFormat := s.detectModelsClientFormat(c)

	// é€‰æ‹©åˆé€‚çš„ç«¯ç‚¹
	ep, err := s.selectEndpointForModels(clientFormat)
	if err != nil {
		s.logger.Error("Failed to select endpoint for models", err, map[string]interface{}{
			"request_id":    requestID,
			"client_format": clientFormat,
		})
		c.JSON(http.StatusServiceUnavailable, gin.H{
			"error": gin.H{
				"type":    "service_unavailable",
				"message": "No suitable endpoint available for models list",
			},
		})
		return
	}

	// æ„å»ºä¸Šæ¸¸è¯·æ±‚
	upstreamURL := s.buildModelsUpstreamURL(ep, clientFormat, path)

	// åˆ›å»ºä¸Šæ¸¸è¯·æ±‚
	req, err := http.NewRequestWithContext(c.Request.Context(), "GET", upstreamURL, nil)
	if err != nil {
		s.logger.Error("Failed to create upstream request", err, map[string]interface{}{
			"request_id": requestID,
		})
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"type":    "internal_error",
				"message": "Failed to create upstream request",
			},
		})
		return
	}

	// è®¾ç½®è®¤è¯å¤´
	authHeader, err := ep.GetAuthHeader()
	if err != nil {
		s.logger.Error("Failed to get auth header", err, map[string]interface{}{
			"request_id": requestID,
			"endpoint":   ep.Name,
		})
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"type":    "auth_error",
				"message": "Failed to get authentication header",
			},
		})
		return
	}

	// æ ¹æ®å®¢æˆ·ç«¯æ ¼å¼è®¾ç½®è®¤è¯
	s.setModelsAuthHeader(req, clientFormat, authHeader)

	// å‘é€è¯·æ±‚
	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		s.logger.Error("Upstream request failed", err, map[string]interface{}{
			"request_id": requestID,
			"endpoint":   ep.Name,
			"url":        upstreamURL,
		})
		c.JSON(http.StatusBadGateway, gin.H{
			"error": gin.H{
				"type":    "upstream_error",
				"message": "Failed to fetch models from upstream",
			},
		})
		return
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		s.logger.Error("Failed to read upstream response", err, map[string]interface{}{
			"request_id": requestID,
		})
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"type":    "response_error",
				"message": "Failed to read upstream response",
			},
		})
		return
	}

	// å¦‚æœä¸Šæ¸¸è¿”å›é”™è¯¯ï¼Œç›´æ¥è¿”å›
	if resp.StatusCode >= 400 {
		c.Data(resp.StatusCode, "application/json", body)
		return
	}

	// è½¬æ¢å“åº”æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
	convertedBody, err := s.convertModelsResponse(body, clientFormat, ep.EndpointType)
	if err != nil {
		s.logger.Error("Failed to convert models response", err, map[string]interface{}{
			"request_id":    requestID,
			"client_format": clientFormat,
			"endpoint_type": ep.EndpointType,
		})
		c.JSON(http.StatusInternalServerError, gin.H{
			"error": gin.H{
				"type":    "conversion_error",
				"message": "Failed to convert models response format",
			},
		})
		return
	}

	// è®¾ç½®å“åº”å¤´å¹¶è¿”å›
	c.Header("Content-Type", "application/json")
	c.Data(http.StatusOK, "application/json", convertedBody)

	s.logger.Info("ğŸ“‹ Models list completed", map[string]interface{}{
		"request_id":    requestID,
		"endpoint":      ep.Name,
		"client_format": clientFormat,
		"status_code":   resp.StatusCode,
	})
}

// detectModelsClientFormat æ£€æµ‹æ¨¡å‹åˆ—è¡¨è¯·æ±‚çš„å®¢æˆ·ç«¯æ ¼å¼
func (s *Server) detectModelsClientFormat(c *gin.Context) string {
	path := c.Request.URL.Path
	authHeader := c.GetHeader("Authorization")
	apiKey := c.GetHeader("x-api-key")
	apiKeyParam := c.Query("key")

	// æ ¹æ®è·¯å¾„å’Œè®¤è¯æ–¹å¼åˆ¤æ–­
	if strings.Contains(path, "/v1beta/models") {
		return "gemini"
	}

	if authHeader != "" && strings.HasPrefix(authHeader, "Bearer ") {
		return "openai"
	}

	if apiKey != "" {
		return "anthropic"
	}

	if apiKeyParam != "" {
		return "gemini"
	}

	// é»˜è®¤è¿”å›openaiæ ¼å¼
	return "openai"
}

// selectEndpointForModels ä¸ºæ¨¡å‹åˆ—è¡¨é€‰æ‹©åˆé€‚çš„ç«¯ç‚¹
func (s *Server) selectEndpointForModels(clientFormat string) (*endpoint.Endpoint, error) {
	endpoints := s.endpointManager.GetAllEndpoints()

	// ä¼˜å…ˆé€‰æ‹©æ”¯æŒç›¸åº”æ ¼å¼çš„ç«¯ç‚¹
	for _, ep := range endpoints {
		if !ep.Enabled {
			continue
		}

		switch clientFormat {
		case "openai":
			if ep.URLOpenAI != "" {
				return ep, nil
			}
		case "anthropic":
			if ep.URLAnthropic != "" {
				return ep, nil
			}
		case "gemini":
			if ep.URLGemini != "" {
				return ep, nil
			}
		}
	}

	return nil, fmt.Errorf("no suitable endpoint found for format: %s", clientFormat)
}

// buildModelsUpstreamURL æ„å»ºä¸Šæ¸¸æ¨¡å‹åˆ—è¡¨URL
func (s *Server) buildModelsUpstreamURL(ep *endpoint.Endpoint, clientFormat, path string) string {
	switch clientFormat {
	case "openai":
		return ep.URLOpenAI + "/v1/models"
	case "anthropic":
		return ep.URLAnthropic + "/v1/models"
	case "gemini":
		return ep.URLGemini + path
	default:
		return ep.URLOpenAI + "/v1/models"
	}
}

// setModelsAuthHeader è®¾ç½®æ¨¡å‹åˆ—è¡¨è¯·æ±‚çš„è®¤è¯å¤´
func (s *Server) setModelsAuthHeader(req *http.Request, clientFormat, authHeader string) {
	switch clientFormat {
	case "openai":
		req.Header.Set("Authorization", authHeader)
	case "anthropic":
		if strings.HasPrefix(authHeader, "Bearer ") {
			req.Header.Set("x-api-key", strings.TrimPrefix(authHeader, "Bearer "))
		} else {
			req.Header.Set("x-api-key", authHeader)
		}
	case "gemini":
		if strings.HasPrefix(authHeader, "Bearer ") {
			req.Header.Set("x-goog-api-key", strings.TrimPrefix(authHeader, "Bearer "))
		} else {
			req.Header.Set("x-goog-api-key", authHeader)
		}
	}
}

// convertModelsResponse è½¬æ¢æ¨¡å‹åˆ—è¡¨å“åº”æ ¼å¼
func (s *Server) convertModelsResponse(body []byte, clientFormat, endpointType string) ([]byte, error) {
	// å¦‚æœå®¢æˆ·ç«¯æ ¼å¼å’Œç«¯ç‚¹ç±»å‹ç›¸åŒï¼Œæ— éœ€è½¬æ¢
	if clientFormat == endpointType {
		return body, nil
	}

	// è§£æåŸå§‹å“åº”
	var originalResp map[string]interface{}
	if err := jsonutils.SafeUnmarshal(body, &originalResp); err != nil {
		return nil, fmt.Errorf("failed to parse response: %w", err)
	}

	// æ ¹æ®éœ€è¦è¿›è¡Œæ ¼å¼è½¬æ¢
	switch clientFormat {
	case "openai":
		return s.convertToOpenAIModelsFormat(originalResp, endpointType)
	case "anthropic":
		return s.convertToAnthropicModelsFormat(originalResp, endpointType)
	case "gemini":
		return s.convertToGeminiModelsFormat(originalResp, endpointType)
	default:
		return body, nil
	}
}

// convertToOpenAIModelsFormat è½¬æ¢ä¸ºOpenAIæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨
func (s *Server) convertToOpenAIModelsFormat(resp map[string]interface{}, sourceFormat string) ([]byte, error) {
	var models []map[string]interface{}

	switch sourceFormat {
	case "anthropic":
		// Anthropicæ ¼å¼é€šå¸¸è¿”å›å­—ç¬¦ä¸²æ•°ç»„
		if data, ok := resp["data"].([]interface{}); ok {
			for _, item := range data {
				if modelID, ok := item.(string); ok {
					models = append(models, map[string]interface{}{
						"id":       modelID,
						"object":   "model",
						"created":  time.Now().Unix(),
						"owned_by": "anthropic",
					})
				}
			}
		}
	case "gemini":
		// Geminiæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨
		if modelsData, ok := resp["models"].([]interface{}); ok {
			for _, item := range modelsData {
				if modelData, ok := item.(map[string]interface{}); ok {
					if name, ok := modelData["name"].(string); ok {
						models = append(models, map[string]interface{}{
							"id":       name,
							"object":   "model",
							"created":  time.Now().Unix(),
							"owned_by": "google",
						})
					}
				}
			}
		}
	}

	result := map[string]interface{}{
		"object": "list",
		"data":   models,
	}

	return jsonutils.SafeMarshal(result)
}

// convertToAnthropicModelsFormat è½¬æ¢ä¸ºAnthropicæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨
func (s *Server) convertToAnthropicModelsFormat(resp map[string]interface{}, sourceFormat string) ([]byte, error) {
	var models []string

	switch sourceFormat {
	case "openai":
		// OpenAIæ ¼å¼è½¬æ¢ä¸ºAnthropicæ ¼å¼
		if data, ok := resp["data"].([]interface{}); ok {
			for _, item := range data {
				if modelData, ok := item.(map[string]interface{}); ok {
					if id, ok := modelData["id"].(string); ok {
						models = append(models, id)
					}
				}
			}
		}
	case "gemini":
		// Geminiæ ¼å¼è½¬æ¢ä¸ºAnthropicæ ¼å¼
		if modelsData, ok := resp["models"].([]interface{}); ok {
			for _, item := range modelsData {
				if modelData, ok := item.(map[string]interface{}); ok {
					if name, ok := modelData["name"].(string); ok {
						models = append(models, name)
					}
				}
			}
		}
	}

	result := map[string]interface{}{
		"data": models,
	}

	return jsonutils.SafeMarshal(result)
}

// convertToGeminiModelsFormat è½¬æ¢ä¸ºGeminiæ ¼å¼çš„æ¨¡å‹åˆ—è¡¨
func (s *Server) convertToGeminiModelsFormat(resp map[string]interface{}, sourceFormat string) ([]byte, error) {
	var models []map[string]interface{}

	switch sourceFormat {
	case "openai":
		// OpenAIæ ¼å¼è½¬æ¢ä¸ºGeminiæ ¼å¼
		if data, ok := resp["data"].([]interface{}); ok {
			for _, item := range data {
				if modelData, ok := item.(map[string]interface{}); ok {
					if id, ok := modelData["id"].(string); ok {
						models = append(models, map[string]interface{}{
							"name":                       id,
							"version":                    "001",
							"displayName":                id,
							"description":                fmt.Sprintf("Model %s", id),
							"inputTokenLimit":            32768,
							"outputTokenLimit":           8192,
							"supportedGenerationMethods": []string{"generateContent"},
						})
					}
				}
			}
		}
	case "anthropic":
		// Anthropicæ ¼å¼è½¬æ¢ä¸ºGeminiæ ¼å¼
		if data, ok := resp["data"].([]interface{}); ok {
			for _, item := range data {
				if modelID, ok := item.(string); ok {
					models = append(models, map[string]interface{}{
						"name":                       modelID,
						"version":                    "001",
						"displayName":                modelID,
						"description":                fmt.Sprintf("Model %s", modelID),
						"inputTokenLimit":            32768,
						"outputTokenLimit":           8192,
						"supportedGenerationMethods": []string{"generateContent"},
					})
				}
			}
		}
	}

	result := map[string]interface{}{
		"models": models,
	}

	return jsonutils.SafeMarshal(result)
}
