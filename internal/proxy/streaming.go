package proxy

import (
	"bytes"
	"compress/gzip"
	"fmt"
	"io"
	"net/http"
	"strings"
	"time"

	"claude-code-codex-companion/internal/conversion"
	"claude-code-codex-companion/internal/endpoint"
	"claude-code-codex-companion/internal/utils"
	"claude-code-codex-companion/internal/validator"
	"github.com/gin-gonic/gin"
)

// streaming.go: æµå¼å¤„ç†æ¨¡å—
// è´Ÿè´£å¤„ç†æ‰€æœ‰ä¸ SSE (Server-Sent Events) ç›¸å…³çš„æµå¼å“åº”é€»è¾‘ã€‚
//
// ç›®æ ‡ï¼š
// - åŒ…å« handleStreamingResponse å‡½æ•°åŠå…¶æ‰€æœ‰è¾…åŠ©å‡½æ•°ã€‚
// - é›†ä¸­å¤„ç†æµå¼å“åº”çš„æ ¼å¼è½¬æ¢ï¼ˆå¦‚ OpenAI SSE -> Anthropic SSEï¼‰ã€‚
// - ç®¡ç†æµå¼å“åº”çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬å¤´éƒ¨è®¾ç½®ã€æ•°æ®åˆ·æ–°å’Œè¿æ¥å…³é—­ã€‚

// handleStreamingResponse å¤„ç†æµå¼å“åº”
func (s *Server) handleStreamingResponse(
	c *gin.Context,
	resp *http.Response,
	req *http.Request,
	ep *endpoint.Endpoint,
	requestID string,
	path string,
	inboundPath string,
	requestBody []byte,
	finalRequestBody []byte,
	originalModel string,
	rewrittenModel string,
	tags []string,
	endpointRequestFormat string,
	actualEndpointFormat string,
	formatDetection *utils.FormatDetectionResult,
	actuallyUsingOpenAIURL bool,
	isCountTokensRequest bool,
	endpointStartTime time.Time,
	attemptNumber int,
	clientRequestFormat string,
	conversionStages *[]string,
	firstByteTime time.Duration,
) (bool, bool, time.Duration, time.Duration) {
	contentEncoding := resp.Header.Get("Content-Encoding")
	var reader io.Reader = resp.Body
	var gzipReader *gzip.Reader
	if s.validator.IsGzipContent(contentEncoding) {
		gz, err := gzip.NewReader(resp.Body)
		if err != nil {
			duration := time.Since(endpointStartTime)
			errMsg := fmt.Errorf("failed to init gzip reader: %w", err)
			if conversionStages != nil {
				setConversionContext(c, *conversionStages)
			}
			s.logSimpleRequest(requestID, ep.GetURLForFormat(endpointRequestFormat), c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, nil, duration, errMsg, true, tags, "", originalModel, rewrittenModel, attemptNumber, ep.GetURLForFormat(endpointRequestFormat))
			c.Set("last_error", errMsg)
			c.Set("last_status_code", resp.StatusCode)
			return false, false, duration, 0
		}
		gzipReader = gz
		reader = gz
	}
	if gzipReader != nil {
		defer gzipReader.Close()
	}

	originalCapture := newLimitedBuffer(responseCaptureLimit)
	reader = io.TeeReader(reader, originalCapture)

	isCodexClient := formatDetection != nil && formatDetection.ClientType == utils.ClientCodex
	if isCodexClient {
		addConversionStage(conversionStages, "response:*->responses")
	}

	validationEndpointType := ep.EndpointType
	if actualEndpointFormat != "" {
		validationEndpointType = actualEndpointFormat
	}

	// å¤åˆ¶ä¸Šæ¸¸å“åº”å¤´ï¼ˆé™¤å»é•¿åº¦ä¸ç¼–ç ï¼‰
	c.Status(resp.StatusCode)
	for key, values := range resp.Header {
		keyLower := strings.ToLower(key)
		switch keyLower {
		case "content-length", "content-encoding":
			continue
		case "content-type":
			continue
		default:
			for _, value := range values {
				c.Header(key, value)
			}
		}
	}

	c.Header("Content-Type", "text/event-stream; charset=utf-8")
	c.Header("Cache-Control", "no-cache")
	c.Header("Connection", "keep-alive")
	c.Header("X-Accel-Buffering", "no")
	c.Header("Content-Length", "")
	c.Header("Content-Encoding", "")

	if ep.ShouldMonitorRateLimit() {
		if err := s.processRateLimitHeaders(ep, resp.Header, requestID); err != nil {
			s.logger.Error("Failed to process rate limit headers", err)
		}
	}

	captureWriter := newTeeCaptureWriter(c.Writer, responseCaptureLimit)
	outWriter := io.Writer(captureWriter)
	var streamErr error

	// æ ¹æ®å®¢æˆ·ç«¯ç±»å‹å’Œä¸Šæ¸¸æ ¼å¼å†³å®šæ˜¯å¦éœ€è¦æµå¼è½¬æ¢
	actualEndpointFormat, streamErr = s.handleStreamingConversion(formatDetection, actualEndpointFormat, reader, outWriter, ep)

	if streamErr != nil {
		duration := time.Since(endpointStartTime)
		errMsg := fmt.Errorf("streaming response failed: %w", streamErr)
		if conversionStages != nil {
			setConversionContext(c, *conversionStages)
		}
		s.logSimpleRequest(requestID, ep.GetURLForFormat(endpointRequestFormat), c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, originalCapture.Bytes(), duration, errMsg, true, tags, "", originalModel, rewrittenModel, attemptNumber, ep.GetURLForFormat(endpointRequestFormat))
		c.Set("last_error", errMsg)
		c.Set("last_status_code", resp.StatusCode)
		return false, false, duration, 0
	}

	if actualEndpointFormat != "" {
		validationEndpointType = actualEndpointFormat
	}

	if flusher, ok := c.Writer.(http.Flusher); ok {
		flusher.Flush()
	}

	finalSample := captureWriter.Captured()
	originalSample := originalCapture.Bytes()

	if len(finalSample) >= responseCaptureLimit {
		s.logger.Debug("Streaming response capture truncated", map[string]interface{}{
			"endpoint":   ep.Name,
			"request_id": requestID,
		})
	}

	if len(finalSample) < responseCaptureLimit && len(finalSample) > 0 {
		if err := s.validator.ValidateResponseWithPath(finalSample, true, validationEndpointType, path, ep.GetURLForFormat(endpointRequestFormat)); err != nil {
			shouldSkip := validator.IsBusinessError(err) && s.config.Blacklist.BusinessErrorSafe
			if shouldSkip {
				s.logger.Info(fmt.Sprintf("Streaming response validation returned business error for endpoint %s: %v", ep.Name, err))
			} else {
				s.logger.Info(fmt.Sprintf("Streaming response validation failed for endpoint %s, trying next endpoint: %v", ep.Name, err))
			}
			duration := time.Since(endpointStartTime)
			if conversionStages != nil {
				setConversionContext(c, *conversionStages)
			}
			s.logSimpleRequest(requestID, ep.GetURLForFormat(endpointRequestFormat), c.Request.Method, path, requestBody, finalRequestBody, c, req, resp, finalSample, duration, err, true, tags, "", originalModel, rewrittenModel, attemptNumber, ep.GetURLForFormat(endpointRequestFormat))
			c.Set("last_error", err)
			c.Set("last_status_code", resp.StatusCode)
			if shouldSkip {
				return false, true, duration, 0
			}
			return false, true, duration, 0
		}
	}

	overrideInfo := ""
	if len(finalSample) > 0 {
		if _, info := s.validator.SmartDetectContentType(finalSample, "text/event-stream; charset=utf-8", resp.StatusCode); info != "" {
			overrideInfo = info
		}
	}

	duration := time.Since(endpointStartTime)
	if conversionStages != nil {
		setConversionContext(c, *conversionStages)
	}
	updateSupportsResponsesContext(c, ep)
	requestLog := s.logger.CreateRequestLog(requestID, ep.GetURLForFormat(endpointRequestFormat), c.Request.Method, path)
	requestLog.RequestBodySize = len(requestBody)
	requestLog.Tags = tags
	requestLog.ContentTypeOverride = overrideInfo
	requestLog.AttemptNumber = attemptNumber
	requestLog.IsStreaming = true
	requestLog.WasStreaming = true

	if thinkingInfo, exists := c.Get("thinking_info"); exists {
		if info, ok := thinkingInfo.(*utils.ThinkingInfo); ok && info != nil {
			requestLog.ThinkingEnabled = info.Enabled
			requestLog.ThinkingBudgetTokens = info.BudgetTokens
		}
	}

	if formatDetection != nil {
		requestLog.ClientType = string(formatDetection.ClientType)
		requestLog.RequestFormat = string(formatDetection.Format)
		requestLog.TargetFormat = ep.EndpointType
		requestLog.FormatConverted = isCodexClient
		requestLog.DetectionConfidence = formatDetection.Confidence
		requestLog.DetectedBy = formatDetection.DetectedBy
	}
	if conversionStages != nil && len(*conversionStages) > 0 {
		requestLog.FormatConverted = true
		requestLog.ConversionPath = strings.Join(*conversionStages, conversionStageSeparator)
	}
	requestLog.SupportsResponsesFlag = getSupportsResponsesFlag(ep)
	requestLog.OriginalRequestURL = c.Request.URL.String()
	requestLog.OriginalRequestHeaders = utils.HeadersToMap(c.Request.Header)
	if len(requestBody) > 0 {
		if s.config.Logging.LogRequestBody != "none" {
			preview, _, _ := buildBodySnapshot(requestBody)
			requestLog.OriginalRequestBody = preview
		}
	}

	if req != nil {
		requestLog.FinalRequestURL = req.URL.String()
		requestLog.FinalRequestHeaders = utils.HeadersToMap(req.Header)
	} else {
		// For streaming responses, construct URL from endpoint info
		requestLog.FinalRequestURL = ep.GetURLForFormat(endpointRequestFormat)
		requestLog.FinalRequestHeaders = make(map[string]string)
	}
	if len(finalRequestBody) > 0 {
		preview, hash, truncated := buildBodySnapshot(finalRequestBody)
		if s.config.Logging.LogRequestBody != "none" {
			requestLog.FinalRequestBody = preview
		}
		requestLog.RequestBody = requestLog.FinalRequestBody
		requestLog.RequestBodyHash = hash
		requestLog.RequestBodyTruncated = truncated
		requestLog.RequestBodySize = len(finalRequestBody)
	} else if len(requestBody) > 0 {
		preview, hash, truncated := buildBodySnapshot(requestBody)
		if s.config.Logging.LogRequestBody != "none" && requestLog.OriginalRequestBody == "" {
			requestLog.OriginalRequestBody = preview
		}
		if requestLog.RequestBody == "" {
			requestLog.RequestBody = requestLog.OriginalRequestBody
		}
		requestLog.RequestBodyHash = hash
		requestLog.RequestBodyTruncated = truncated
	}

	requestLog.OriginalResponseHeaders = utils.HeadersToMap(resp.Header)
	if len(originalSample) > 0 && s.config.Logging.LogResponseBody != "none" {
		preview, _, _ := buildBodySnapshot(originalSample)
		requestLog.OriginalResponseBody = preview
	}

	finalHeaders := make(map[string]string)
	for key := range resp.Header {
		values := c.Writer.Header().Values(key)
		if len(values) > 0 {
			finalHeaders[key] = values[0]
		}
	}
	requestLog.FinalResponseHeaders = finalHeaders
	if len(finalSample) > 0 && s.config.Logging.LogResponseBody != "none" {
		preview, _, _ := buildBodySnapshot(finalSample)
		requestLog.FinalResponseBody = preview
	}

	requestLog.RequestHeaders = requestLog.FinalRequestHeaders
	if requestLog.RequestBody == "" {
		requestLog.RequestBody = requestLog.OriginalRequestBody
	}
	requestLog.ResponseHeaders = requestLog.FinalResponseHeaders
	if requestLog.ResponseBody == "" {
		requestLog.ResponseBody = requestLog.FinalResponseBody
	}

	if len(requestBody) > 0 {
		extractedModel := utils.ExtractModelFromRequestBody(string(requestBody))
		if originalModel != "" {
			requestLog.Model = originalModel
			requestLog.OriginalModel = originalModel
		} else {
			requestLog.Model = extractedModel
			requestLog.OriginalModel = extractedModel
		}
		if rewrittenModel != "" {
			requestLog.RewrittenModel = rewrittenModel
			requestLog.ModelRewriteApplied = rewrittenModel != requestLog.OriginalModel
		}
		requestLog.SessionID = utils.ExtractSessionIDFromRequestBody(string(requestBody))
	}

	s.logger.UpdateRequestLog(requestLog, req, resp, finalSample, duration, nil)
	s.logger.LogRequest(requestLog)

	if ep.EndpointType == "openai" && inboundPath == "/responses" && ep.NativeCodexFormat == nil {
		// åŸºäºä¸Šæ¸¸åŸå§‹æ ·æœ¬åˆ¤æ–­æ˜¯å¦ä¸ºåŸç”Ÿ Codex /responses æµ
		isResponsesNative := bytes.Contains(originalSample, []byte("response.output_text.delta")) ||
			bytes.Contains(originalSample, []byte("response.created")) ||
			bytes.Contains(originalSample, []byte("\"type\":\"response.completed\""))
		if isResponsesNative {
			trueValue := true
			ep.NativeCodexFormat = &trueValue
			updateSupportsResponsesContext(c, ep)
			s.logger.Info("Auto-detected: endpoint natively supports Codex format", map[string]interface{}{
				"endpoint": ep.Name,
			})
			if ep.OpenAIPreference == "" || ep.OpenAIPreference == "auto" {
				ep.OpenAIPreference = "responses"
				s.PersistEndpointLearning(ep)
			}
		}
	}

	if formatDetection != nil && formatDetection.ClientType == utils.ClientCodex && ep.EndpointType == "openai" {
		if inboundPath == "/responses" {
			// ä½¿ç”¨åŸå§‹æ ·æœ¬åˆ¤æ–­æ˜¯å¦åŸç”ŸCodexæ”¯æŒ
			isResponsesNative := bytes.Contains(originalSample, []byte("response.output_text.delta")) ||
				bytes.Contains(originalSample, []byte("response.created")) ||
				bytes.Contains(originalSample, []byte("\"type\":\"response.completed\""))
			if isResponsesNative {
				s.updateEndpointCodexSupport(ep, true)
			}
		}
	} else if formatDetection != nil && formatDetection.ClientType == utils.ClientClaudeCode && ep.EndpointType == "anthropic" {
		s.updateEndpointCodexSupport(ep, false)
	}

	if isCountTokensRequest {
		ep.MarkCountTokensSupport(true)
	}

	c.Set("last_error", nil)
	c.Set("last_status_code", resp.StatusCode)

	return true, false, duration, firstByteTime
}

// handleStreamingConversion æ ¹æ®å®¢æˆ·ç«¯ç±»å‹å’Œä¸Šæ¸¸æ ¼å¼å†³å®šæµå¼è½¬æ¢ç­–ç•¥
func (s *Server) handleStreamingConversion(formatDetection *utils.FormatDetectionResult, upstreamFormat string, reader io.Reader, writer io.Writer, ep *endpoint.Endpoint) (string, error) {
	if formatDetection == nil {
		// æ— æ ¼å¼æ£€æµ‹ä¿¡æ¯ï¼Œç›´æ¥é€ä¼ 
		_, err := io.Copy(writer, reader)
		return upstreamFormat, err
	}

	clientType := formatDetection.ClientType
	expectedFormat := s.getExpectedFormatForClient(clientType)

	// å¦‚æœå®¢æˆ·ç«¯æœŸæœ›æ ¼å¼ä¸ä¸Šæ¸¸æ ¼å¼åŒ¹é…ï¼Œæ— éœ€è½¬æ¢
	if expectedFormat == upstreamFormat || expectedFormat == "" {
		_, err := io.Copy(writer, reader)
		return upstreamFormat, err
	}

	// éœ€è¦æ ¼å¼è½¬æ¢
	if err := s.convertStreamingResponse(expectedFormat, upstreamFormat, reader, writer, ep); err != nil {
		return upstreamFormat, err
	}
	return expectedFormat, nil
}

// getExpectedFormatForClient æ ¹æ®å®¢æˆ·ç«¯ç±»å‹è¿”å›æœŸæœ›çš„ä¸Šæ¸¸æ ¼å¼
func (s *Server) getExpectedFormatForClient(clientType utils.ClientType) string {
	switch clientType {
	case utils.ClientCodex:
		// Codex å®¢æˆ·ç«¯æœŸæœ› Responses API æ ¼å¼ï¼Œå¯¹åº” openai ç«¯ç‚¹
		return "openai"
	case utils.ClientClaudeCode:
		// Claude Code å®¢æˆ·ç«¯æœŸæœ› Anthropic æ ¼å¼ï¼Œå¯¹åº” anthropic ç«¯ç‚¹
		return "anthropic"
	case utils.ClientGemini:
		// Gemini å®¢æˆ·ç«¯æœŸæœ› Gemini æ ¼å¼ï¼Œå¯¹åº” gemini ç«¯ç‚¹
		return "gemini"
	default:
		return ""
	}
}

// convertStreamingResponse æ‰§è¡Œæµå¼å“åº”æ ¼å¼è½¬æ¢
func (s *Server) convertStreamingResponse(targetFormat, sourceFormat string, reader io.Reader, writer io.Writer, ep *endpoint.Endpoint) error {
	conversionKey := sourceFormat + "_to_" + targetFormat

	// è®°å½•æµå¼è½¬æ¢æ“ä½œ
	s.logger.Info("ğŸ”„ Streaming format conversion", map[string]interface{}{
		"conversion":    conversionKey,
		"source_format": sourceFormat,
		"target_format": targetFormat,
		"endpoint":      ep.Name,
	})

	switch conversionKey {
	case "openai_to_openai":
		// OpenAI Chat Completions SSE â†’ OpenAI Responses SSE (Codex)
		if s.conversionManager != nil {
			_, err := s.conversionManager.ConvertStream(
				"chat_sse_to_responses",
				ep.Name,
				reader,
				writer,
				conversion.StreamChatCompletionsToResponses, // unified
				nil,
			)
			return err
		}
		return conversion.StreamChatCompletionsToResponses(reader, writer)

	case "anthropic_to_openai":
		// Anthropic SSE â†’ OpenAI Chat Completions SSE
		return conversion.StreamAnthropicSSEToOpenAI(reader, writer)

	case "openai_to_anthropic":
		// OpenAI Chat Completions SSE â†’ Anthropic SSE
		return conversion.StreamOpenAISSEToAnthropic(reader, writer)

	case "gemini_to_openai":
		// Gemini SSE â†’ OpenAI Chat Completions SSE
		return conversion.StreamGeminiSSEToOpenAI(reader, writer)

	case "gemini_to_anthropic":
		// Gemini SSE â†’ Anthropic SSE
		return conversion.StreamGeminiSSEToAnthropic(reader, writer)

	case "openai_to_gemini":
		// OpenAI Chat Completions SSE â†’ Gemini SSE
		// TODO: Implement StreamOpenAIToGemini
		return fmt.Errorf("streaming conversion from OpenAI to Gemini not yet implemented")

	case "anthropic_to_gemini":
		// Anthropic SSE â†’ Gemini SSE
		// TODO: Implement StreamAnthropicToGemini
		return fmt.Errorf("streaming conversion from Anthropic to Gemini not yet implemented")

	default:
		// ä¸æ”¯æŒçš„è½¬æ¢ç»„åˆï¼Œè¿”å›é”™è¯¯
		return fmt.Errorf("unsupported streaming conversion: %s to %s", sourceFormat, targetFormat)
	}
}
