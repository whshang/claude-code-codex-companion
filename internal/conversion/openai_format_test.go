package conversion

import (
	"encoding/json"
	"testing"
)

// æµ‹è¯• Chat â†’ Internal â†’ Responses å®Œæ•´è½¬æ¢é“¾ï¼ˆåŒ…å«æ‰€æœ‰æ–°å­—æ®µï¼‰
func TestChatToResponsesFullFieldMapping(t *testing.T) {
	// æ„é€ åŒ…å«æ‰€æœ‰å­—æ®µçš„ Chat Completions è¯·æ±‚
	chatJSON := `{
		"model": "gpt-4o-mini",
		"messages": [
			{"role": "system", "content": "You are helpful."},
			{"role": "user", "content": "Hello"}
		],
		"temperature": 0.7,
		"top_p": 0.9,
		"max_completion_tokens": 1024,
		"presence_penalty": 0.5,
		"frequency_penalty": 0.3,
		"logit_bias": {"123": 2.0, "456": -1.5},
		"n": 3,
		"stop": ["STOP", "END"],
		"user": "test-user",
		"parallel_tool_calls": true,
		"response_format": {
			"type": "json_object",
			"schema": {"type": "object", "properties": {"result": {"type": "string"}}}
		},
		"tools": [{
			"type": "function",
			"function": {
				"name": "search",
				"description": "Search the web",
				"parameters": {"type": "object", "properties": {"query": {"type": "string"}}}
			}
		}],
		"tool_choice": "auto"
	}`

	factory := NewAdapterFactory(nil)
	chatAdapter := factory.OpenAIChatAdapter()
	responsesAdapter := factory.OpenAIResponsesAdapter()

	// é˜¶æ®µ1: Chat â†’ Internal
	internalReq, err := chatAdapter.ParseRequestJSON([]byte(chatJSON))
	if err != nil {
		t.Fatalf("ParseRequestJSON failed: %v", err)
	}

	// éªŒè¯ Internal ç»“æ„æ‰€æœ‰å­—æ®µ
	if internalReq.Model != "gpt-4o-mini" {
		t.Errorf("Expected model gpt-4o-mini, got %s", internalReq.Model)
	}
	if internalReq.Temperature == nil || *internalReq.Temperature != 0.7 {
		t.Errorf("Temperature not mapped correctly")
	}
	if internalReq.TopP == nil || *internalReq.TopP != 0.9 {
		t.Errorf("TopP not mapped correctly")
	}
	if internalReq.MaxCompletionTokens == nil || *internalReq.MaxCompletionTokens != 1024 {
		t.Errorf("MaxCompletionTokens not mapped correctly")
	}
	// ğŸ†• éªŒè¯é‡‡æ ·å‚æ•°
	if internalReq.PresencePenalty == nil || *internalReq.PresencePenalty != 0.5 {
		t.Errorf("PresencePenalty not mapped correctly")
	}
	if internalReq.FrequencyPenalty == nil || *internalReq.FrequencyPenalty != 0.3 {
		t.Errorf("FrequencyPenalty not mapped correctly")
	}
	if len(internalReq.LogitBias) != 2 {
		t.Errorf("LogitBias not mapped correctly, got %d items", len(internalReq.LogitBias))
	}
	if internalReq.N == nil || *internalReq.N != 3 {
		t.Errorf("N not mapped correctly")
	}
	if len(internalReq.Stop) != 2 {
		t.Errorf("Stop sequences not mapped correctly")
	}
	// ğŸ†• éªŒè¯ ResponseFormat
	if internalReq.ResponseFormat == nil {
		t.Fatal("ResponseFormat should not be nil")
	}
	if internalReq.ResponseFormat.Type != "json_object" {
		t.Errorf("ResponseFormat.Type expected json_object, got %s", internalReq.ResponseFormat.Type)
	}
	if len(internalReq.ResponseFormat.Schema) == 0 {
		t.Error("ResponseFormat.Schema should not be empty")
	}

	// é˜¶æ®µ2: Internal â†’ Responses
	responsesJSON, err := responsesAdapter.BuildRequestJSON(internalReq)
	if err != nil {
		t.Fatalf("BuildRequestJSON failed: %v", err)
	}

	var responsesReq OpenAIResponsesRequest
	if err := json.Unmarshal(responsesJSON, &responsesReq); err != nil {
		t.Fatalf("Failed to unmarshal responses request: %v", err)
	}

	// éªŒè¯ Responses ç»“æ„æ‰€æœ‰å­—æ®µ
	if responsesReq.Model != "gpt-4o-mini" {
		t.Errorf("Responses model mismatch")
	}
	if responsesReq.PresencePenalty == nil || *responsesReq.PresencePenalty != 0.5 {
		t.Errorf("Responses PresencePenalty not preserved")
	}
	if responsesReq.FrequencyPenalty == nil || *responsesReq.FrequencyPenalty != 0.3 {
		t.Errorf("Responses FrequencyPenalty not preserved")
	}
	if len(responsesReq.LogitBias) != 2 {
		t.Errorf("Responses LogitBias not preserved")
	}
	if responsesReq.N == nil || *responsesReq.N != 3 {
		t.Errorf("Responses N not preserved")
	}
	if len(responsesReq.Stop) != 2 {
		t.Errorf("Responses Stop not preserved")
	}
	if responsesReq.ResponseFormat == nil || responsesReq.ResponseFormat.Type != "json_object" {
		t.Error("Responses ResponseFormat not preserved")
	}
}

// æµ‹è¯• Responses â†’ Internal â†’ Chat å®Œæ•´è½¬æ¢é“¾ï¼ˆåŒ…å«åŒè·¯å¾„å›é€€ï¼‰
func TestResponsesToChatFullFieldMapping(t *testing.T) {
	// æµ‹è¯• input å­—æ®µè·¯å¾„
	responsesJSON := `{
		"model": "gpt-4o",
		"input": [
			{"role": "user", "content": [{"type": "input_text", "text": "Hello from input"}]}
		],
		"temperature": 0.8,
		"presence_penalty": 1.0,
		"frequency_penalty": 0.5,
		"logit_bias": {"789": 3.0},
		"n": 2,
		"stop": ["TERMINATE"],
		"response_format": {"type": "json_schema", "schema": {"type": "object"}}
	}`

	factory := NewAdapterFactory(nil)
	responsesAdapter := factory.OpenAIResponsesAdapter()
	chatAdapter := factory.OpenAIChatAdapter()

	// é˜¶æ®µ1: Responses â†’ Internal
	internalReq, err := responsesAdapter.ParseRequestJSON([]byte(responsesJSON))
	if err != nil {
		t.Fatalf("ParseRequestJSON failed: %v", err)
	}

	// éªŒè¯æ‰€æœ‰å­—æ®µ
	if internalReq.PresencePenalty == nil || *internalReq.PresencePenalty != 1.0 {
		t.Errorf("PresencePenalty not parsed correctly")
	}
	if internalReq.N == nil || *internalReq.N != 2 {
		t.Errorf("N not parsed correctly")
	}
	if len(internalReq.Messages) != 1 {
		t.Fatalf("Expected 1 message, got %d", len(internalReq.Messages))
	}
	if len(internalReq.Messages[0].Contents) == 0 || internalReq.Messages[0].Contents[0].Text != "Hello from input" {
		t.Errorf("Message content not parsed from input field")
	}

	// é˜¶æ®µ2: Internal â†’ Chat
	chatJSON, err := chatAdapter.BuildRequestJSON(internalReq)
	if err != nil {
		t.Fatalf("BuildRequestJSON failed: %v", err)
	}

	var chatReq OpenAIRequest
	if err := json.Unmarshal(chatJSON, &chatReq); err != nil {
		t.Fatalf("Failed to unmarshal chat request: %v", err)
	}

	// éªŒè¯ Chat ç»“æ„ä¿ç•™äº†æ‰€æœ‰å­—æ®µ
	if chatReq.PresencePenalty == nil || *chatReq.PresencePenalty != 1.0 {
		t.Errorf("Chat PresencePenalty not preserved")
	}
	if chatReq.N == nil || *chatReq.N != 2 {
		t.Errorf("Chat N not preserved")
	}
	if chatReq.ResponseFormat == nil || chatReq.ResponseFormat.Type != "json_schema" {
		t.Error("Chat ResponseFormat not preserved")
	}
}

// æµ‹è¯•åŒè·¯å¾„å›é€€ï¼šmessages ä½œä¸º input çš„å›é€€
func TestResponsesMessagesFallback(t *testing.T) {
	// ä½¿ç”¨ messages è€Œä¸æ˜¯ input
	responsesJSON := `{
		"model": "gpt-4o",
		"messages": [
			{"role": "user", "content": [{"type": "input_text", "text": "Hello from messages"}]}
		]
	}`

	factory := NewAdapterFactory(nil)
	responsesAdapter := factory.OpenAIResponsesAdapter()

	internalReq, err := responsesAdapter.ParseRequestJSON([]byte(responsesJSON))
	if err != nil {
		t.Fatalf("ParseRequestJSON failed: %v", err)
	}

	if len(internalReq.Messages) != 1 {
		t.Fatalf("Expected 1 message from messages fallback, got %d", len(internalReq.Messages))
	}
	if internalReq.Messages[0].Contents[0].Text != "Hello from messages" {
		t.Errorf("Message content not parsed from messages fallback")
	}
}

// æµ‹è¯• LogitBias å…‹éš†ï¼ˆé˜²æ­¢å…±äº«å¼•ç”¨ï¼‰
func TestLogitBiasCloning(t *testing.T) {
	original := map[string]float64{"123": 1.0, "456": -1.0}
	cloned := cloneLogitBias(original)

	// ä¿®æ”¹å…‹éš†ä¸åº”å½±å“åŸå§‹
	cloned["123"] = 999.0

	if original["123"] != 1.0 {
		t.Errorf("Original LogitBias was mutated, expected 1.0 got %f", original["123"])
	}
	if cloned["123"] != 999.0 {
		t.Errorf("Cloned LogitBias not independent")
	}
}

// æµ‹è¯• ResponseFormat è½¬æ¢
func TestResponseFormatConversion(t *testing.T) {
	openaiRF := &OpenAIResponseFormat{
		Type: "json_schema",
		Schema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"name": map[string]interface{}{"type": "string"},
			},
		},
	}

	// OpenAI â†’ Internal
	internalRF := convertOpenAIResponseFormatToInternal(openaiRF)
	if internalRF == nil {
		t.Fatal("Internal ResponseFormat should not be nil")
	}
	if internalRF.Type != "json_schema" {
		t.Errorf("Type not converted correctly")
	}
	if len(internalRF.Schema) == 0 {
		t.Error("Schema not converted")
	}

	// Internal â†’ OpenAI
	convertedBack := convertInternalResponseFormatToOpenAI(internalRF)
	if convertedBack == nil {
		t.Fatal("Converted back ResponseFormat should not be nil")
	}
	if convertedBack.Type != "json_schema" {
		t.Errorf("Type not converted back correctly")
	}
	if len(convertedBack.Schema) == 0 {
		t.Error("Schema not converted back")
	}

	// æµ‹è¯• nil å¤„ç†
	if convertOpenAIResponseFormatToInternal(nil) != nil {
		t.Error("Should return nil for nil input")
	}
	if convertInternalResponseFormatToOpenAI(nil) != nil {
		t.Error("Should return nil for nil input")
	}
}

// æµ‹è¯•è¾¹ç•Œæƒ…å†µï¼šç©º LogitBias å’Œ Stop
func TestEmptyCollections(t *testing.T) {
	chatJSON := `{
		"model": "gpt-4o",
		"messages": [{"role": "user", "content": "test"}],
		"logit_bias": {},
		"stop": []
	}`

	factory := NewAdapterFactory(nil)
	chatAdapter := factory.OpenAIChatAdapter()

	internalReq, err := chatAdapter.ParseRequestJSON([]byte(chatJSON))
	if err != nil {
		t.Fatalf("ParseRequestJSON failed: %v", err)
	}

	// ç©º LogitBias åº”è¯¥è¢«ä¿ç•™ä¸ºénilç©ºmapï¼Œç©º Stop å¯ä»¥æ˜¯nilï¼ˆå› ä¸ºä½¿ç”¨append([]string(nil)ä¼šåˆ›å»ºæ–°åˆ‡ç‰‡ï¼‰
	if internalReq.LogitBias == nil {
		t.Error("Empty LogitBias should not be nil")
	}
	if len(internalReq.LogitBias) != 0 {
		t.Error("Empty LogitBias should have 0 items")
	}
	// Stop ä½¿ç”¨ append([]string(nil), ...) åˆ›å»ºï¼Œæ‰€ä»¥ç©ºæ•°ç»„ä¼šå˜æˆnilï¼Œè¿™æ˜¯æ­£å¸¸çš„
	if len(internalReq.Stop) != 0 {
		t.Error("Empty Stop should have 0 items")
	}
}
